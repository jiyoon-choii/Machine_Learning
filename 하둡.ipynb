{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하둡이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대용량 데이터를 적은비용으로 더 빠르게 분석할 수 있는 소프트웨어\n",
    "- 여러개의 컴퓨터를 하나로 묶어 대용량 데이터를 처리\n",
    "- 저장된 파일을 분산된 서버의 CPU와 메모리 자원을 이용해 더 빠르게 분석\n",
    "- 마스터노드 => 슬레이브 노드를 관리해주는 메인 컴퓨터\n",
    "- 슬레이브 노드1, 2, 3, 4 ... => 나머지 컴퓨터\n",
    "- 하둡 커먼, HDFS, 맵 리듀스로 구성\n",
    "- 마스터 노드가 각각의 슬레이브 노드를 처리하고 저장하게 관리해 줌\n",
    "- 슬레이브 노드가 망가지면 마스터 노드가 안에 있는 자료를 복제함\n",
    "- 세컨더리 네임 노드 마스터 노드의 자료를 동기화 받아 마스터 노드에 문제가 있을 시\n",
    "- 세컨더리 네임 노드가 그 기능을 대신 함. => 물리적으로 다른 컴퓨터에 지정해 줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하둡 클러스터 구축을 위한 준비사항\n",
    "\n",
    "- 리눅스 운영체제 서버\n",
    "- 자바\n",
    "- 하둡 패키지 10.0\n",
    "- ssh 설정\n",
    "- 하둡 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하둡 다운로드 방법\n",
    "\n",
    "- https://hadoop.apache.org \n",
    "- 노란색 버튼 클릭\n",
    "- 3.1.2 다운로드\n",
    "- binary 다운로드\n",
    "- http://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz 다운"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하둡 설정 파일\n",
    "\n",
    "- conf/masters => 세컨더리 네임노드가 동작하는 노드를 명시\n",
    "- conf/slaves = > 데이터노드와 태스크 트레커가 동작하는 노드를 명시\n",
    "- conf/haddop=env.sh => 하둡이 실행하는 모든 프로세스에 적용되는 시스템 환경 관리\n",
    "- conf/core-site.xml => 하둡 분산 파일 시스템과 하둡 맵리듀스 모두에 적용할 수 있음\n",
    "- conf/hdfs-site => 하둡 분산파일 시스템 설정 스크립트\n",
    "- conf/mapred-site.xml => 하둡 맵리듀스 설정 스크립트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 환경변수 설정\n",
    "\n",
    "- 프롬프트 창에 where java 로 자바 경로 확인\n",
    "- 내pc 우클릭 => 속성 => 고급시스템설정 => 환경변수 클릭\n",
    "- 시스템 변수에 새로 추가하기 클릭해 JAVA_HOME 이름으로 jdk경로 추가\n",
    "- path 클릭해서 새로만들기로\n",
    "- jdk절대경로 입력하고\\bin 입력\n",
    "- cmd창 다 닫고 다시 실행하기\n",
    "- where java로 자바 위치 변경 됬는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 압축풀기\n",
    "\n",
    "- 하둡 다운받은 것과\n",
    "- 트렐로에서 hadoop-3.1.2_winutils => 다운 받기 => 윈도우에서 실행할 수 있게 해주는 파일\n",
    "- 로컬디스크 C에서 bigdata 빈 폴더 생성\n",
    "- 안에 다운 받은 것들 압축 풀기\n",
    "- hadoop-3.1.2_winutils bin안에 있는 폴더에 있는 파일을 복사해서\n",
    "- hadoop-3.1.2 폴더 안에 있는 bin에 덮어 씌우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하둡 종류\n",
    "\n",
    "- 표준 오픈소스 하둡 배포판 => apache hadoop\n",
    "- 밴더 배포판"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hdfs(hadoop distributed file system)\n",
    "\n",
    "- 파일의 분산 저장이 목적\n",
    "- 네임노드와 데이터노드로 구성\n",
    "    - 마스터 노드 => 파일 시스템 이미지와 변경기록을 저장\n",
    "    - 세컨더리 노드 => 마스터노드의 파일과 파일의 사본을 저장 \n",
    "    - 데이터 노드 => 데이터파일의 블록을 저장, 디폴트 블록의 크기는 128MB\n",
    "- 블럭 단위로 파일 관리\n",
    "- 복제 기증을 통해 안정성/신뢰성 보장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 환경변수 설정 2\n",
    "\n",
    "- 시스템 변수에 hadoop-3.1.2가 있는 경로 추가\n",
    "- path 편집해서 hadoop-3.1.2의 경로에\\bin 으로 해주기\n",
    "- 프롬프트 창에서 set 입력 => 경로 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하둡 설정파일 수정\n",
    "\n",
    "- C:\\bigdata\\hadoop-3.1.2\\hadoop-3.1.2\\etc\\hadoop => 경로 들어가기\n",
    "- hadoop-env.cmd => 윈도우용 고치기 => vscode에서 열기\n",
    "- 25번째 줄에 \n",
    "- set JAVA_HOME=%JAVA_HOME% 을 jdk경로\n",
    "- C:\\Program\" \"Files\\Java\\jdk1.8.0_211 로 수정하거나\n",
    "- C:\\PROGRA~1\\Java\\jdk1.8.0_211 로 설정\n",
    "- 밑에 있는 경로는 cmd창에서 cd \\ 치고 dir /x 쳐서 확인\n",
    "- 90번째 줄 set HADOOP_IDENT_STRING=%USERNAME%에 있는 유저네임을\n",
    "- cmd에 서 set 쳐서 확인 후 %지우고 변경해주기\n",
    "- 그리고 그 밑에 줄에\n",
    "- set HADOOP_PREFIX=C:\\bigdata\\hadoop-3.1.3\\hadoop-3.1.2 => 내 경로 설정\n",
    "- set HADOOP_CONF_DIR=%HADOOP_PREFIX\\etc\\hadoop\n",
    "- set YARN_CONF_DIR=%HADOOP_CONF_DIR%\n",
    "- set PATH=%PATH%;%HADOOP_PREFIX%\\bin;%HADOOP_PREFIX%\\sbin 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### core-site.xml\n",
    "\n",
    "- vscode로 열어서 \n",
    "- <configuration>  \n",
    "    <property>  \n",
    "        <name>fs.default.name</name>  \n",
    "        <value>hdfs://0.0.0.0:9000</value>  \n",
    "    </property>  \n",
    "    <property>  \n",
    "        <name>hadoop.tmp.dir</name>  \n",
    "        <value>/C:/bigdata/hadoop-3.1.2/hadoop-3.1.2/tmp</value>  \n",
    "    </property>  \n",
    "</configuration>  \n",
    "\n",
    "- tmp폴더만들어서 폴더 경로 지정해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yarn-site.xml  : 소스 관리해주는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers : local host "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트 : 'ping localhost' 로 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmd를 관리자 권한으로 열기 :\n",
    "명령 프롬프트 - 오른쪽 마우스 - 관리자 권한으로 실행\n",
    "- hdfs namenode -format \n",
    "'Storage directory \\tmp\\hadoop-admin\\dfs\\name has been successfully formatted.' 가 떠야 함 \n",
    "- start-dfs.cmd \n",
    "- start-yarn.cmd\n",
    "- jps => 5개 떠야 함\n",
    "\n",
    "- http://localhost:9870/\n",
    "\n",
    "- 프롬프트 끌 땐 stop 해야 함 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://rdatasciencecases.org/Data/Airline/ : 자료 가져다쓰는 오픈데이터 사이트 \n",
    "- 2007, 2008 zip 파일 다운로드\n",
    "#디렉토리 만들기 \n",
    "- 다운로드한 폴더에서 shift+우클릭-파워쉘열기 \n",
    "- hdfs dfs -mkdir /airline/ : 내용 안 떠야 잘 된 것임 \n",
    "- hdfs dfs -ls\n",
    "- hdfs dfs -ls /\n",
    "\n",
    "- dir\n",
    "\n",
    "#파일 복사하기 \n",
    "- hdfs dfs -put ./2008.csv /airline/\n",
    "- hdfs dfs -ls /airline/\n",
    "\n",
    "#데이터가 하둡에 적용되었는지 확인 \n",
    "- 싸이트-Live nodes-Blocks(내가 사용하고 있는 용량) \n",
    "\n",
    "#trello-speech.zip : 폴더 채로 넣기 \n",
    "- hdfs dfs -put ./speech /\n",
    "- hdfs dfs -ls /\n",
    "\n",
    "- hadoop jar WordCount.jar /speech/ /output/word_count\n",
    "- hdfs dfs -ls /output/word_count\n",
    "- hdfs dfs -cat /output/word_count/part-r-00000         \n",
    "#파일 읽기 \n",
    "- hdfs dfs -head /output/word_count/part-r-00000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat,text : 파일 내용 보기\n",
    "mkdir[-p] : 디렉토리 생성\n",
    "put, get : 파일 복사( 로컬 <-> HDFS )\n",
    "cp,mv : 파일 복사, 이동( HDFS <-> HDFS )\n",
    "chmod, chown, chgrp : 권한, 소유주, 그룹 변경 \n",
    "*리눅스 명령어 공부하면 알게 됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#동작이 안 될때 확인\n",
    "-safemode is off : safemode 켜져있는지 꺼져있는지 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
